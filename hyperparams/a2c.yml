antenna4x4-v1:               
  #gamma: 0.8                                #0.99
  #learning_rate: lin_3e-4                       # default 0.00007 
  learning_rate: !!float 3e-4
  n_envs: 30                            
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  #normalize_advantage: False
  #ent_coef: 0.001
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"
                       

antenna4x4-v2:               
  n_envs: 20
  n_timesteps: !!float 5e5
  policy: 'MlpPolicy'
  gamma: 0.9999
  normalize_advantage: True
  max_grad_norm: 0.5
  use_rms_prop: True
  gae_lambda: 0.8
  n_steps: 32
  learning_rate: lin_0.00195
  ent_coef: 0.006844205648137561
  vf_coef: 0.42788016145892316
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"



#Tuned on 17.07
antenna4x4-v1_1:
  n_envs: 30
  n_timesteps: !!float 1e6
  policy: 'MultiInputPolicy'
  gamma: 0.9999
  normalize_advantage: True
  max_grad_norm: 0.5
  use_rms_prop: True
  gae_lambda: 0.8
  n_steps: 32
  #learning_rate: !!float 3e-4
  ##learning_rate: 0.00195
  learning_rate: lin_0.00195
  ent_coef: 0.006844205648137561
  vf_coef: 0.42788016145892316
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"


#To compare the result with Backtracking
antenna3x4-v1_1:
  n_envs: 20
  n_timesteps: !!float 10e5
  policy: 'MultiInputPolicy'
  gamma: 0.9999
  normalize_advantage: True
  max_grad_norm: 0.5
  use_rms_prop: True
  gae_lambda: 0.8
  n_steps: 8
  learning_rate: lin_0.000195
  ent_coef: 0.006844205648137561
  vf_coef: 0.42788016145892316
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned on 30.08
antenna3x4-v1_1:
  n_envs: 40
  n_timesteps: !!float 10e5
  policy: 'MultiInputPolicy'
  gamma: 0.9
  normalize_advantage: False
  max_grad_norm: 5.0
  use_rms_prop: True
  gae_lambda: 0.92
  n_steps: 8
  learning_rate: 0.007566785861472658
  ent_coef: 0.00030326019001703007
  vf_coef:  0.05367410386766924
  policy_kwargs: "dict(
                       activation_fn=nn.Tanh,
                       net_arch=dict(pi=[64, 64], vf=[64, 64])
                       )"

#Tuned on 01-02.09.2024
antenna3x4-v1_1:
  n_envs: 40
  n_timesteps: !!float 5e5
  policy: 'MultiInputPolicy'
  gamma: 0.98
  normalize_advantage: True
  max_grad_norm: 2
  use_rms_prop: True
  gae_lambda: 0.92
  n_steps: 2
  learning_rate: lin_0.000195
  ent_coef: 0.0030565850454063294
  vf_coef:  0.07243133325050177
  policy_kwargs: "dict(
                       activation_fn=nn.Tanh,
                       net_arch=dict(pi=[64, 64], vf=[64, 64])
                       )"


# Optimised values on 03.12.2024
antenna3x4-v1.2:
  n_envs: 40
  n_timesteps: !!float 1e6
  policy: 'MultiInputPolicy'
  gamma: 0.95
  normalize_advantage: False
  max_grad_norm: 0.8
  use_rms_prop: False
  gae_lambda: 0.98
  n_steps: 128
  learning_rate:  5.5374327021893094e-05
  ent_coef: 0.00617218540287641
  vf_coef:  0.30012806242162304
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

antenna3x4-v2.0:
  n_envs: 60
  n_timesteps: !!float 4e6
  policy: 'MultiInputPolicy'
  gamma: 0.99
  normalize_advantage: True
  max_grad_norm: 2.0
  use_rms_prop: False
  gae_lambda: 0.9
  n_steps: 4
  learning_rate:  0.001
  ent_coef: 0.0000
  vf_coef:  0.7
  policy_kwargs: "dict(
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"



